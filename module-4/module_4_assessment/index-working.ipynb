{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Module 4 Assessment</h1>\n",
    "\n",
    "## Overview\n",
    "\n",
    "This assessment is designed to test your understanding of the Mod 4 material. It covers:\n",
    "\n",
    "* Calculus, Cost Function, and Gradient Descent\n",
    "* Extensions to Linear Models\n",
    "* Introduction to Logistic Regression\n",
    "\n",
    "\n",
    "Read the instructions carefully. You will be asked both to write code and respond to a few short answer questions.\n",
    "\n",
    "### Note on the short answer questions\n",
    "\n",
    "For the short answer questions please use your own words. The expectation is that you have not copied and pasted from an external source, even if you consult another source to help craft your response. While the short answer questions are not necessarily being assessed on grammatical correctness or sentence structure, do your best to communicate yourself clearly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Calculus, Cost Function, and Gradient Descent [Suggested Time: 25 min]\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![best fit line](visuals/best_fit_line.png)\n",
    "\n",
    "The best fit line that goes through the scatterplot up above can be generalized in the following equation: $$y = mx + b$$\n",
    "\n",
    "Of all the possible lines, we can prove why that particular line was chosen using the plot down below:\n",
    "\n",
    "![](visuals/cost_curve.png)\n",
    "\n",
    "where RSS is defined as the residual sum of squares:\n",
    "\n",
    "$$ \n",
    "\\begin{align}\n",
    "RSS &= \\sum_{i=1}^n(actual - expected)^2 \\\\\n",
    "&= \\sum_{i=1}^n(y_i - \\hat{y})^2 \\\\\n",
    "&= \\sum_{i=1}^n(y_i - (mx_i + b))^2\n",
    "\\end{align}\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What is a more generalized name for the RSS function above? What are the parameters of RSS? How is it related to machine learning models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cost Function.  \n",
    "- The parameters are the actual y (target) variables and the predicted ones, which are defined by the linear regression equation, and therefore its parameters, after the regression is fit to create the equation.  \n",
    "- RSS can measure the scale of error for a given machine learning model, and therefore a model can be designed to minimize that error to find a best fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Would you rather choose a $m$ value of 0.09 or 0.06 from the RSS curve up above?   What is the relation between the position on the cost curve, the error, and the slope of the line?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 0.06 because RSS is lower.\n",
    "- The cost curve is the error values (y-axis) of the cost function plotted for slope values (x-axis), which are a parameter of the predicted values and therefore of the cost function as well. The RSS decreases as you increase slope from 0 to ~0.05 and then begins to increase as the slope increases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](visuals/gd.png)\n",
    "\n",
    "### 3. Using the gradient descent visual from above, explain why the distance between each step is getting smaller as more steps occur with gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculation of the step size is in part based on the error at the current location on the curve (i.e. they are directly proportion), so as the minimum is approached the error decreases and therefore the calculated step size also decreases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. What is the purpose of a learning rate in gradient descent? Explain how a very small and a very large learning rate would affect the gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning rate is a hyperparameter that is applied to the calculation of the step size. As it decreases the step sizes decrease, meaning the descent process will take longer but is less likely to step over the local minimum and find an incorrect minimum or fail to converge at all. As the learning rate increases the step sizes are longer, meaning the descent process will take longer, but could fail to find the local minimum if it is too large and keeps stepping past the minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Extensions to Linear Regression [Suggested Time: 25 min]\n",
    "---\n",
    "\n",
    "In this section, you're going to be creating linear models that are more complicated than a simple linear regression. In the cells below, we are importing relevant modules that you might need later on. We also load and prepare the dataset for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "import pickle\n",
    "from sklearn.metrics import mean_squared_error, roc_curve, roc_auc_score, accuracy_score\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>147.042500</td>\n",
       "      <td>23.264000</td>\n",
       "      <td>30.554000</td>\n",
       "      <td>14.022500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>85.854236</td>\n",
       "      <td>14.846809</td>\n",
       "      <td>21.778621</td>\n",
       "      <td>5.217457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>74.375000</td>\n",
       "      <td>9.975000</td>\n",
       "      <td>12.750000</td>\n",
       "      <td>10.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>149.750000</td>\n",
       "      <td>22.900000</td>\n",
       "      <td>25.750000</td>\n",
       "      <td>12.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>218.825000</td>\n",
       "      <td>36.525000</td>\n",
       "      <td>45.100000</td>\n",
       "      <td>17.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>296.400000</td>\n",
       "      <td>49.600000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TV       radio   newspaper       sales\n",
       "count  200.000000  200.000000  200.000000  200.000000\n",
       "mean   147.042500   23.264000   30.554000   14.022500\n",
       "std     85.854236   14.846809   21.778621    5.217457\n",
       "min      0.700000    0.000000    0.300000    1.600000\n",
       "25%     74.375000    9.975000   12.750000   10.375000\n",
       "50%    149.750000   22.900000   25.750000   12.900000\n",
       "75%    218.825000   36.525000   45.100000   17.400000\n",
       "max    296.400000   49.600000  114.000000   27.000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('raw_data/advertising.csv').drop('Unnamed: 0',axis=1)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('sales', axis=1)\n",
    "y = data['sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and testing set. Do not change the random state please!\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. We'd like to add a bit of complexity to the model created in the example above, and we will do it by adding some polynomial terms. Write a function to calculate train and test error for different polynomial degrees.\n",
    "\n",
    "This function should:\n",
    "* take `degree` as a parameter that will be used to create polynomial features to be used in a linear regression model\n",
    "* create a PolynomialFeatures object for each degree and fit a linear regression model using the transformed data\n",
    "* calculate the mean square error for each level of polynomial\n",
    "* return the `train_error` and `test_error` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_regression(degree):\n",
    "    \"\"\"\n",
    "    Calculate train and test errorfor a linear regression with polynomial features.\n",
    "    (Hint: use PolynomialFeatures)\n",
    "    \n",
    "    input: Polynomial degree\n",
    "    output: Mean squared error for train and test set\n",
    "    \"\"\"\n",
    "    poly = PolynomialFeatures(degree=degree)\n",
    "    poly_X_train = pd.DataFrame(poly.fit_transform(X_train))\n",
    "    poly_X_test = pd.DataFrame(poly.fit_transform(X_test))\n",
    "    reg = LinearRegression()\n",
    "    reg_fitted = reg.fit(poly_X_train, y_train)\n",
    "    train_pred = reg_fitted.predict(poly_X_train)\n",
    "    test_pred = reg_fitted.predict(poly_X_test)\n",
    "\n",
    "    train_error = mean_squared_error(y_train, train_pred) \n",
    "    test_error = mean_squared_error(y_test, test_pred)\n",
    "    return train_error, test_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try out your new function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.18179109287494452, 1.9522596244542125)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polynomial_regression(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check your answers\n",
    "\n",
    "MSE for degree 3:\n",
    "- Train: 0.2423596735839209\n",
    "- Test: 0.15281375973923944\n",
    "\n",
    "MSE for degree 4:\n",
    "- Train: 0.18179109317368244\n",
    "- Test: 1.9522597174462015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. What is the optimal number of degrees for our polynomial features in this model? In general, how does increasing the polynomial degree relate to the Bias/Variance tradeoff?  (Note that this graph shows RMSE and not MSE.)\n",
    "\n",
    "<img src =\"visuals/rsme_poly_2.png\" width = \"600\">\n",
    "\n",
    "<!---\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "degree = list(range(1, 10 + 1))\n",
    "ax.plot(degree, error_train[0:len(degree)], \"-\", label=\"Train Error\")\n",
    "ax.plot(degree, error_test[0:len(degree)], \"-\", label=\"Test Error\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xlabel(\"Polynomial Feature Degree\")\n",
    "ax.set_ylabel(\"Root Mean Squared Error\")\n",
    "ax.legend()\n",
    "ax.set_title(\"Relationship Between Degree and Error\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"visuals/rsme_poly.png\",\n",
    "            dpi=150,\n",
    "            bbox_inches=\"tight\")\n",
    "--->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3rd degree polynomial features should be chosen because they minimize the testing RMSE.  \n",
    "- As the polynomial degree is increased, the model becomes more complex/flexible. Depending on the underlying structure of the data and its relationship to the target, this may initially lead to a more closely fit model as more complex relationships are introduced and the bias is reduced without a significant increase in variance. Eventually further increases in polynomial degree will lead to overfitting of the data and the variance will increase substantially and the model won't generalize very well. The goal is to find the sweet spot where increased bias improves accuracy without too much variance to undermine the ability for the model to generalize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. In general what methods would you can use to reduce overfitting and underfitting? Provide an example for both and explain how each technique works to reduce the problems of underfitting and overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Overfitting could potentially be reduced by removing features that aren't contributing much to the model's predictions. Lasso regression is a potential option for identifying the features that can be safely removed.\n",
    "- Underfitting could potentially be reduced by introducing interactions and/or polynomial features to capture more complex relationships within the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. What is the difference between the two types of regularization for linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ridge penalizes the square of the coefficients and has the effect of reducing the size of coefficients, which reduces model complexity.\n",
    "- Lasso penalizes the absolute value of the coefficients and has the effect of setting some coefficients equal to 0, which results in feature selection in addition to reducing model complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Why is scaling input variables a necessary step before regularization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling prevents a particular parameter from being penalized simply because the scale of that feature is different than the scale of another feature. Since the regularization is based on the magnitude of the coefficients, a feature with a larger scale will need smaller coefficients than a feature with a smaller scale to have a similar impact on determing the target. Scaling levels the playing field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Introduction to Logistic Regression [Suggested Time: 25 min]\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!---\n",
    "# load data\n",
    "ads_df = pd.read_csv(\"raw_data/social_network_ads.csv\")\n",
    "\n",
    "# one hot encode categorical feature\n",
    "def is_female(x):\n",
    "    \"\"\"Returns 1 if Female; else 0\"\"\"\n",
    "    if x == \"Female\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "        \n",
    "ads_df[\"Female\"] = ads_df[\"Gender\"].apply(is_female)\n",
    "ads_df.drop([\"User ID\", \"Gender\"], axis=1, inplace=True)\n",
    "ads_df.head()\n",
    "\n",
    "# separate features and target\n",
    "X = ads_df.drop(\"Purchased\", axis=1)\n",
    "y = ads_df[\"Purchased\"]\n",
    "\n",
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=19)\n",
    "\n",
    "# preprocessing\n",
    "scale = StandardScaler()\n",
    "scale.fit(X_train)\n",
    "X_train = scale.transform(X_train)\n",
    "X_test = scale.transform(X_test)\n",
    "\n",
    "# save preprocessed train/test split objects\n",
    "pickle.dump(X_train, open(\"write_data/social_network_ads/X_train_scaled.pkl\", \"wb\"))\n",
    "pickle.dump(X_test, open(\"write_data/social_network_ads/X_test_scaled.pkl\", \"wb\"))\n",
    "pickle.dump(y_train, open(\"write_data/social_network_ads/y_train.pkl\", \"wb\"))\n",
    "pickle.dump(y_test, open(\"write_data/social_network_ads/y_test.pkl\", \"wb\"))\n",
    "\n",
    "# build model\n",
    "model = LogisticRegression(C=1e5, solver=\"lbfgs\")\n",
    "model.fit(X_train, y_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# create confusion matrix\n",
    "# tn, fp, fn, tp\n",
    "cnf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "cnf_matrix\n",
    "\n",
    "# build confusion matrix plot\n",
    "plt.imshow(cnf_matrix,  cmap=plt.cm.Blues) #Create the basic matrix.\n",
    "\n",
    "# Add title and Axis Labels\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "# Add appropriate Axis Scales\n",
    "class_names = set(y_test) #Get class labels to add to matrix\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "\n",
    "# Add Labels to Each Cell\n",
    "thresh = cnf_matrix.max() / 2. #Used for text coloring below\n",
    "#Here we iterate through the confusion matrix and append labels to our visualization.\n",
    "for i, j in itertools.product(range(cnf_matrix.shape[0]), range(cnf_matrix.shape[1])):\n",
    "        plt.text(j, i, cnf_matrix[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cnf_matrix[i, j] > thresh else \"black\")\n",
    "\n",
    "# Add a Side Bar Legend Showing Colors\n",
    "plt.colorbar()\n",
    "\n",
    "# Add padding\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"visuals/cnf_matrix.png\",\n",
    "            dpi=150,\n",
    "            bbox_inches=\"tight\")\n",
    "--->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cnf matrix](visuals/cnf_matrix.png)\n",
    "\n",
    "### 1. Using the confusion matrix up above, calculate precision, recall, and F-1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Precision = \\frac{\\text{Number of True Positives}}{\\text{Number of Predicted Positives}}$$  \n",
    "  \n",
    "$$Recall = \\frac{\\text{Number of True Positives}}{\\text{Number of Actual Total Positives}}$$  \n",
    "  \n",
    "$$F1-Score = 2\\ \\frac{Precision\\ x\\ Recall}{Precision + Recall}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = 30/(30+4)\n",
    "recall = 30/(30+12)\n",
    "f1_score = 2 * (precision*recall)/(precision+recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8823529411764706\n",
      "0.7142857142857143\n",
      "0.7894736842105262\n"
     ]
    }
   ],
   "source": [
    "print(precision)\n",
    "print(recall)\n",
    "print(f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  What is a real life example of when you would care more about recall than precision? Make sure to include information about errors in your explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of when you would care more about recall than precision is when making medical diagnoses because it is most important to correctly diagnose people who have the disease. This may increase type I error, but it also reduces type II error, which is the ultimate goal. The harm of treating someone without the disease (type I) is less than not treating someone with the disease (type II)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!---\n",
    "# save preprocessed train/test split objects\n",
    "X_train = pickle.load(open(\"write_data/social_network_ads/X_train_scaled.pkl\", \"rb\"))\n",
    "X_test = pickle.load(open(\"write_data/social_network_ads/X_test_scaled.pkl\", \"rb\"))\n",
    "y_train = pickle.load(open(\"write_data/social_network_ads/y_train.pkl\", \"rb\"))\n",
    "y_test = pickle.load(open(\"write_data/social_network_ads/y_test.pkl\", \"rb\"))\n",
    "\n",
    "# build model\n",
    "model = LogisticRegression(C=1e5, solver=\"lbfgs\")\n",
    "model.fit(X_train, y_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "labels = [\"Age\", \"Estimated Salary\", \"Female\", \"All Features\"]\n",
    "colors = sns.color_palette(\"Set2\")\n",
    "plt.figure(figsize=(10, 8))\n",
    "# add one ROC curve per feature\n",
    "for feature in range(3):\n",
    "    # female feature is one hot encoded so it produces an ROC point rather than a curve\n",
    "    # for this reason, female will not be included in the plot at all since it is\n",
    "    # disingeneuous to call it a curve.\n",
    "    if feature == 2:\n",
    "        pass\n",
    "    else:\n",
    "        X_train_feat = X_train[:, feature].reshape(-1, 1)\n",
    "        X_test_feat = X_test[:, feature].reshape(-1, 1)\n",
    "        logreg = LogisticRegression(fit_intercept=False, C=1e12, solver='lbfgs')\n",
    "        model_log = logreg.fit(X_train_feat, y_train)\n",
    "        y_score = model_log.decision_function(X_test_feat)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_score)\n",
    "        lw = 2\n",
    "        plt.plot(fpr, tpr, color=colors[feature],\n",
    "                 lw=lw, label=labels[feature])\n",
    "\n",
    "# add one ROC curve with all the features\n",
    "model_log = logreg.fit(X_train, y_train)\n",
    "y_score = model_log.decision_function(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_score)\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color=colors[3], lw=lw, label=labels[3])\n",
    "\n",
    "# create foundation of the plot\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.yticks([i / 20.0 for i in range(21)])\n",
    "plt.xticks([i / 20.0 for i in range(21)])\n",
    "plt.xlabel(\"False positive rate\")\n",
    "plt.ylabel(\"True positive rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"visuals/many_roc.png\",\n",
    "            dpi=150,\n",
    "            bbox_inches=\"tight\")\n",
    "--->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Pick the best ROC curve from this graph and explain your choice. \n",
    "\n",
    "*Note: each ROC curve represents one model, each labeled with the feature(s) inside each model*.\n",
    "\n",
    "<img src = \"visuals/many_roc.png\" width = \"700\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'All Features' would be best because it has the largest area under the curve (AUC) (i.e. its line is furthest to the left and top of the graph) and almost always performs better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!---\n",
    "# sorting by 'Purchased' and then dropping the last 130 records\n",
    "dropped_df = ads_df.sort_values(by=\"Purchased\")[:-130]\n",
    "dropped_df.reset_index(inplace=True)\n",
    "pickle.dump(dropped_df, open(\"write_data/sample_network_data.pkl\", \"wb\"))\n",
    "--->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original classifier has an accuracy score of 0.956.\n",
      "The original classifier has an area under the ROC curve of 0.836.\n"
     ]
    }
   ],
   "source": [
    "network_df = pickle.load(open(\"write_data/sample_network_data.pkl\", \"rb\"))\n",
    "\n",
    "# partion features and target \n",
    "X = network_df.drop(\"Purchased\", axis=1)\n",
    "y = network_df[\"Purchased\"]\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2019)\n",
    "\n",
    "# scale features\n",
    "scale = StandardScaler()\n",
    "scale.fit(X_train)\n",
    "X_train = scale.transform(X_train)\n",
    "X_test = scale.transform(X_test)\n",
    "\n",
    "# build classifier\n",
    "model = LogisticRegression(C=1e5, solver=\"lbfgs\")\n",
    "model.fit(X_train,y_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# get the accuracy score\n",
    "print(f\"The original classifier has an accuracy score of {round(accuracy_score(y_test, y_test_pred), 3)}.\")\n",
    "\n",
    "# get the area under the curve from an ROC curve\n",
    "y_score = model.decision_function(X_test)\n",
    "fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "auc = round(roc_auc_score(y_test, y_score), 3)\n",
    "print(f\"The original classifier has an area under the ROC curve of {auc}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. The model above has an accuracy score that might be too good to believe. Using `y.value_counts()`, explain how `y` is affecting the accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    257\n",
       "1     13\n",
       "Name: Purchased, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04814814814814815"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "13/(257+13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy score is too good to be true because classes are imbalanced (y contains many more 0's than 1's). In fact, 4.8% of the y-values are 1, so choosing 0 every single time would result in an accuracy of 95.2% which is only 0.4% lower than the original classifier, so the model is providing very little additional value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. What methods would you use to address the issues mentioned up above in question 4? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some methods to address class imbalance:  \n",
    "- Undersampling the over-represented class is an option, but this would be ill-advised considering how little data there is to begin with. After undersampling, you wounldn't be left with much data to model and confidence in your model would be in question.\n",
    "- Oversampling the under-represented class is an option, but this would similarly be impacted by how few samples have a 1 as the y-value because each of those samples would be repeated many times.\n",
    "- SMOTE is a preferable option because it creates synthetic data within the under-represented class' samples' vector space."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
